{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VJpl9Q_b46Qw"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!git clone https://github.com/Nazar1997/Sparse_vector.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!git clone https://github.com/vladislareon/z_dna data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!git clone https://github.com/AIRI-Institute/GENA_LM.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils import data\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from collections import Counter\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy\n",
    "from tqdm import trange\n",
    "from tqdm import tqdm\n",
    "from datetime import datetime\n",
    "import sys\n",
    "import os\n",
    "import seaborn as sns\n",
    "from matplotlib import pyplot as plt\n",
    "from joblib import Parallel, delayed, dump, load\n",
    "from matplotlib import pyplot as plt\n",
    "from Sparse_vector.sparse_vector import SparseVector\n",
    "from scipy.signal import convolve2d, convolve\n",
    "import time\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from sklearn.metrics import roc_auc_score, f1_score\n",
    "from IPython.display import clear_output\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "mjV3FIq446Qy"
   },
   "outputs": [],
   "source": [
    "ASSEMBLY_d = {}\n",
    "chroms_d = {}\n",
    "all_features_d = {}\n",
    "groups_d = {}\n",
    "feature_names_d = {}\n",
    "ZDNA_d = {}\n",
    "black_list_d = {}\n",
    "DNA_d = {}\n",
    "DNA_features_d = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LFoX-tho46Qz"
   },
   "source": [
    "# HG38"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lY9iMMRJ46Q0"
   },
   "outputs": [],
   "source": [
    "ASSEMBLY = \"ZDNA_2016\"\n",
    "chroms = [f'chr{i}' for i in list(range(1, 23)) + ['X', 'Y']]\n",
    "all_features = sorted([i[:-4] for i in os.listdir('data/hg38_features/sparse/') if i.endswith('.pkl')])\n",
    "groups = ['DNase-seq', 'Histone', 'RNA polymerase', 'TFs and others']\n",
    "feature_names = [i for i in all_features if (i.split('_')[0] in groups)]\n",
    "ZDNA = load('data/hg38_zdna/sparse/ZDNA_cousine.pkl')\n",
    "black_list = load('blacklist_hg38_v2.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HgyBOHF846Q0",
    "outputId": "2391a329-1771-4596-f94d-c1b879f57c71"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 24/24 [00:11<00:00,  2.03it/s]\n"
     ]
    }
   ],
   "source": [
    "def chrom_reader(chrom):\n",
    "    files = sorted([i for i in os.listdir(f'data/hg38_dna/') if f\"{chrom}_\" in i])\n",
    "    return ''.join([load(f\"data/hg38_dna/{file}\") for file in files])\n",
    "\n",
    "\n",
    "DNA = {chrom:chrom_reader(chrom) for chrom in tqdm(chroms)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xqdlLIPF46Q0"
   },
   "outputs": [],
   "source": [
    "mode = 'hg38'\n",
    "ASSEMBLY_d[mode] = ASSEMBLY\n",
    "chroms_d[mode] = chroms\n",
    "all_features_d[mode] = all_features\n",
    "groups_d[mode] = groups\n",
    "feature_names_d[mode] = feature_names\n",
    "ZDNA_d[mode] = ZDNA\n",
    "black_list_d[mode] = black_list\n",
    "DNA_d[mode] = DNA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ISnQnA0P46Q1"
   },
   "source": [
    "# Data part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Bi5P_5I946Q2"
   },
   "outputs": [],
   "source": [
    "mode = 'hg38'\n",
    "ASSEMBLY = ASSEMBLY_d[mode]\n",
    "chroms = chroms_d[mode]\n",
    "all_features = all_features_d[mode]\n",
    "groups = groups_d[mode]\n",
    "feature_names = feature_names_d[mode]\n",
    "ZDNA = ZDNA_d[mode]\n",
    "black_list = black_list_d[mode]\n",
    "DNA = DNA_d[mode]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9JCIi1cJ46Q2",
    "outputId": "20f166d4-c08b-490f-c42b-661cb8aa3774"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3556520/3556520 [01:41<00:00, 34958.58it/s]\n",
      "100%|██████████| 3459907/3459907 [01:40<00:00, 34343.67it/s]\n",
      "100%|██████████| 2832793/2832793 [01:22<00:00, 34296.16it/s]\n",
      "100%|██████████| 2717350/2717350 [01:21<00:00, 33444.92it/s]\n",
      "100%|██████████| 2593403/2593403 [01:14<00:00, 34936.69it/s]\n",
      "100%|██████████| 2440085/2440085 [01:12<00:00, 33878.58it/s]\n",
      "100%|██████████| 2276371/2276371 [01:07<00:00, 33632.66it/s]\n",
      "100%|██████████| 2073409/2073409 [00:59<00:00, 34713.51it/s]\n",
      "100%|██████████| 1977067/1977067 [00:52<00:00, 37688.06it/s]\n",
      "100%|██████████| 1911391/1911391 [00:57<00:00, 33176.07it/s]\n",
      "100%|██████████| 1929808/1929808 [00:55<00:00, 34901.11it/s]\n",
      "100%|██████████| 1903932/1903932 [00:55<00:00, 34428.97it/s]\n",
      "100%|██████████| 1633776/1633776 [00:47<00:00, 34337.04it/s]\n",
      "100%|██████████| 1529195/1529195 [00:40<00:00, 37551.51it/s]\n",
      "100%|██████████| 1457016/1457016 [00:37<00:00, 38601.52it/s]\n",
      "100%|██████████| 1290547/1290547 [00:35<00:00, 36410.65it/s]\n",
      "100%|██████████| 1189392/1189392 [00:33<00:00, 35622.31it/s]\n",
      "100%|██████████| 1148189/1148189 [00:32<00:00, 35731.65it/s]\n",
      "100%|██████████| 837394/837394 [00:23<00:00, 35472.66it/s]\n",
      "100%|██████████| 920630/920630 [00:30<00:00, 30654.57it/s]\n",
      "100%|██████████| 667285/667285 [00:17<00:00, 38821.79it/s]\n",
      "100%|██████████| 725978/725978 [00:18<00:00, 39997.75it/s]\n",
      "100%|██████████| 2229155/2229155 [01:03<00:00, 35318.21it/s]\n",
      "100%|██████████| 817534/817534 [00:17<00:00, 46350.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49624\n",
      "40396746\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "width = 70\n",
    "\n",
    "np.random.seed(10)\n",
    "\n",
    "ints_in = []\n",
    "ints_out = []\n",
    "\n",
    "\n",
    "for chrm in chroms:\n",
    "    for st in trange(0, ZDNA[chrm].shape - width, width):\n",
    "        interval = [st, min(st + width, ZDNA[chrm].shape)]\n",
    "        N_count = sum([bp == \"N\" for bp in DNA[chrm][interval[0]:interval[1]]])\n",
    "        bl_count = black_list[chrm][interval[0]:interval[1]].sum()\n",
    "        if N_count > width / 2 or bl_count > 0:\n",
    "            continue\n",
    "        else:\n",
    "            if ZDNA[chrm][interval[0]: interval[1]].any():\n",
    "                ints_in.append([chrm, int(interval[0]), int(interval[1]), 1])\n",
    "            else:\n",
    "                ints_out.append([chrm, int(interval[0]), int(interval[1]), 0])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(len(ints_in))\n",
    "print(len(ints_out))\n",
    "\n",
    "ints_in_full = ints_in\n",
    "ints_out_full = ints_out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0hHSvlwq46Q2",
    "outputId": "edd0a897-d4af-4402-de26-0db189bcffd2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49624\n",
      "148872\n"
     ]
    }
   ],
   "source": [
    "ints_in = ints_in_full\n",
    "ints_out = [ints_out_full[i] for i in np.random.choice(range(len(ints_out_full)),\n",
    "                                                    size=len(ints_in) * 3, replace=False)]\n",
    "print(len(ints_in))\n",
    "print(len(ints_out))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "MlDQdN1946Q2"
   },
   "outputs": [],
   "source": [
    "equalized = np.array(ints_in + ints_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "TY5fU_hc46Q3"
   },
   "outputs": [],
   "source": [
    "divisions = list(StratifiedKFold(5, shuffle=True,\n",
    "                                 random_state=42).split(equalized, [f\"{elem[3]}_{elem[0]}\"\n",
    "                                         for i, elem\n",
    "                                         in enumerate(equalized)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qupQsEkD46Q3",
    "outputId": "310cc885-4692-4809-c903-ee002a362efc"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(119097, 39699, 39700)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_intervals, test_intervals = train_test_split(equalized, test_size=0.2, shuffle=True) # Basic train_test_split for now\n",
    "train_intervals, val_intervals = train_test_split(train_intervals, test_size=0.25, shuffle=True)\n",
    "len(train_intervals), len(val_intervals), len(test_intervals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = 'cuda'\n",
    "else:\n",
    "    device = 'cpu'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "p3Bvo9iJZ_tt",
    "tags": []
   },
   "source": [
    "## Загрузка модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from GENA_LM.src.gena_lm.modeling_bert import BertForTokenClassification\n",
    "from transformers import AutoTokenizer\n",
    "import json\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "# tokenizer = AutoTokenizer.from_pretrained('AIRI-Institute/gena-lm-bert-base-t2t')\n",
    "model = BertForTokenClassification.from_pretrained('AIRI-Institute/gena-lm-bert-base-t2t', num_labels=2)\n",
    "# model = BertForTokenClassification.from_pretrained('gena-lm-bert-base-t2t', num_labels=2)\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "# load tokenizer with a changed tokenizer.json file. All tokens are no longer than 5\n",
    "tokenizer = AutoTokenizer.from_pretrained('tokenizer_folder')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "GF-VAVUQXjXk"
   },
   "outputs": [],
   "source": [
    "vocab = tokenizer.get_vocab()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "BvZ_Sdl8V8hy"
   },
   "outputs": [],
   "source": [
    "label2id = vocab\n",
    "id2label = {id_ : label for label, id_ in label2id.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FqrQ-V16WASe"
   },
   "outputs": [],
   "source": [
    "class DNADataset(Dataset):\n",
    "    def __init__(self, chroms,\n",
    "                 dna_source,\n",
    "                 labels, intervals, tokenizer, threshold=0.5):\n",
    "        self.chroms = chroms\n",
    "        self.dna_source = dna_source\n",
    "        self.labels = labels\n",
    "        self.intervals = intervals\n",
    "        self.threshold = threshold # for labeling based on percentage\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.intervals)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        interval = self.intervals[idx]\n",
    "        chrom = interval[0]\n",
    "        begin = int(interval[1])\n",
    "        end = int(interval[2])\n",
    "        sequence = self.dna_source[chrom][begin:end].upper()\n",
    "\n",
    "        y = self.labels[interval[0]][int(interval[1]):int(interval[2])]\n",
    "        labels_by_tokens = []\n",
    "        X = tokenizer(sequence, truncation=True, padding=True)\n",
    "        toks = X['input_ids']\n",
    "        i = 0\n",
    "        for token in toks:\n",
    "            if '[' in id2label[token]:\n",
    "                labels_by_tokens.append(-100)\n",
    "            else:\n",
    "                labels_tokens = y[i:i + len(id2label[token])]\n",
    "                if labels_tokens.sum() / len(labels_tokens) > self.threshold:\n",
    "                    labels_by_tokens.append(1)\n",
    "                else:\n",
    "                    labels_by_tokens.append(0)\n",
    "                i += len(id2label[token])\n",
    "        labels_by_tokens = torch.tensor(labels_by_tokens, dtype=torch.int64)\n",
    "        X['labels'] = labels_by_tokens\n",
    "        return X\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HarfW0eSaPEf",
    "outputId": "8bdb81ae-881d-466c-e3b3-40263e344d36"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input_ids': [1, 87, 35, 101, 2], 'token_type_ids': [0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1]}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# an example of sequence tokenization\n",
    "res = tokenizer(\"AGTGAGCGCC\", truncation=True, padding=True)\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "P7fFxHmZWDGM"
   },
   "outputs": [],
   "source": [
    "thr = 0.7\n",
    "val_dataset_dna = DNADataset(chroms, DNA, ZDNA, val_intervals, tokenizer, threshold=thr)\n",
    "train_dataset_dna = DNADataset(chroms, DNA, ZDNA, train_intervals, tokenizer, threshold=thr)\n",
    "test_dataset_dna = DNADataset(chroms, DNA, ZDNA, test_intervals, tokenizer, threshold=thr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3tpPO58sWjBn",
    "outputId": "8d9b8ecb-d873-4cae-c79d-dc9786b6472a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GENA_LM.src.gena_lm.modeling_bert\n"
     ]
    }
   ],
   "source": [
    "module_name = model.__class__.__module__\n",
    "print(module_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "kuXLhhVm7SPK"
   },
   "outputs": [],
   "source": [
    "from transformers import DataCollatorForTokenClassification\n",
    "\n",
    "data_collator = DataCollatorForTokenClassification(tokenizer=tokenizer, padding=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GENA_LM.src.gena_lm.modeling_bert.BertForTokenClassification"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cls = getattr(importlib.import_module(module_name), 'BertForTokenClassification')\n",
    "cls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForTokenClassification were not initialized from the model checkpoint at gena-lm-bert-base-t2t and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BertForTokenClassification(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(32000, 768, padding_idx=3)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x BertLayer(\n",
       "          (pre_attention_ln): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (post_attention_ln): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (softmax): Softmax(dim=-1)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = cls.from_pretrained('gena-lm-bert-base-t2t')\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "lVs4o4cW6x8t"
   },
   "outputs": [],
   "source": [
    "from transformers import AutoModelForTokenClassification, TrainingArguments, Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "import evaluate\n",
    "mcc = evaluate.load(\"matthews_correlation\")\n",
    "f1_metric = evaluate.load(\"f1\")\n",
    "accuracy_metric = evaluate.load(\"accuracy\")\n",
    "precision_metric = evaluate.load(\"precision\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Current block is for LORA fine-tuning. If you don't want to use LORA, skip this block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_trainable_parameters(model):\n",
    "    \"\"\"\n",
    "    Prints the number of trainable parameters in the model.\n",
    "    \"\"\"\n",
    "    trainable_params = 0\n",
    "    all_param = 0\n",
    "    for _, param in model.named_parameters():\n",
    "        all_param += param.numel()\n",
    "        if param.requires_grad:\n",
    "            trainable_params += param.numel()\n",
    "    print(\n",
    "        f\"trainable params: {trainable_params} || all params: {all_param} || trainable%: {100 * trainable_params / all_param}\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "from peft import get_peft_config, PeftModel, PeftConfig, get_peft_model, LoraConfig, TaskType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "peft_config = LoraConfig(\n",
    "    task_type=TaskType.TOKEN_CLS, inference_mode=False, r=16, lora_alpha=16, lora_dropout=0.1, bias=\"all\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 693,506 || all params: 110,619,652 || trainable%: 0.6269\n"
     ]
    }
   ],
   "source": [
    "model = get_peft_model(model, peft_config)\n",
    "model.print_trainable_parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gena_module_name = model.__class__.__module__\n",
    "print(gena_module_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AM4E8CywW6Yz"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Detected kernel version 3.10.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='4655' max='4655' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [4655/4655 18:46, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Mcc</th>\n",
       "      <th>F1</th>\n",
       "      <th>Precision</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.027900</td>\n",
       "      <td>0.037984</td>\n",
       "      <td>0.986232</td>\n",
       "      <td>0.879155</td>\n",
       "      <td>0.885869</td>\n",
       "      <td>0.856095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.027000</td>\n",
       "      <td>0.036614</td>\n",
       "      <td>0.986755</td>\n",
       "      <td>0.881853</td>\n",
       "      <td>0.888665</td>\n",
       "      <td>0.870133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.025800</td>\n",
       "      <td>0.036815</td>\n",
       "      <td>0.986935</td>\n",
       "      <td>0.883768</td>\n",
       "      <td>0.890433</td>\n",
       "      <td>0.869942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.023800</td>\n",
       "      <td>0.037764</td>\n",
       "      <td>0.986751</td>\n",
       "      <td>0.881140</td>\n",
       "      <td>0.888049</td>\n",
       "      <td>0.873914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.023100</td>\n",
       "      <td>0.041673</td>\n",
       "      <td>0.986131</td>\n",
       "      <td>0.878224</td>\n",
       "      <td>0.885001</td>\n",
       "      <td>0.855456</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=4655, training_loss=0.025496649614082115, metrics={'train_runtime': 1127.3053, 'train_samples_per_second': 528.238, 'train_steps_per_second': 4.129, 'total_flos': 7254613553995080.0, 'train_loss': 0.025496649614082115, 'epoch': 5.0})"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 32\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "\n",
    "    predictions = np.argmax(logits, axis=2)\n",
    "    \n",
    "    p = []\n",
    "    l = []\n",
    "    for prs, lbls in zip(predictions, labels):\n",
    "        for pr, lbl in zip(prs, lbls):\n",
    "            if lbl != -100:\n",
    "                p.append(pr)\n",
    "                l.append(lbl)\n",
    "                \n",
    "    mcc_score = mcc.compute(predictions=p, references=l)[\"matthews_correlation\"]\n",
    "    f1_score = f1_metric.compute(predictions=p, references=l)[\"f1\"]\n",
    "    precision = precision_metric.compute(references=l, predictions=p)['precision']\n",
    "    accuracy = accuracy_metric.compute(references=l, predictions=p)['accuracy']\n",
    "    return {\"Accuracy\": accuracy, \"MCC\": mcc_score, \"F1\": f1_score, \"Precision\": precision}\n",
    "\n",
    "args = TrainingArguments(\n",
    "    output_dir=\"run_110_6\",\n",
    "    learning_rate=2e-5,\n",
    "    lr_scheduler_type=\"constant_with_warmup\",\n",
    "    warmup_ratio=0.1,\n",
    "    optim='adamw_torch',\n",
    "    label_names=[\"labels\"],\n",
    "    weight_decay=0.01,\n",
    "    per_device_train_batch_size=batch_size,\n",
    "    per_device_eval_batch_size=batch_size,\n",
    "    num_train_epochs=10,\n",
    "    eval_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    logging_strategy=\"steps\",\n",
    "    load_best_model_at_end=True,\n",
    "    # report_to=\"wandb\",\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=args,\n",
    "    train_dataset=train_dataset_dna,\n",
    "    eval_dataset=val_dataset_dna,\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "trainer.can_return_loss = True\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), 'model_zdna_70_110_after_510_thr_0_3_0_6_07_max_5-10ep.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='547' max='547' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [547/547 00:31]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.02524162270128727,\n",
       " 'eval_Accuracy': 0.9904477788957797,\n",
       " 'eval_MCC': 0.881465697103664,\n",
       " 'eval_F1': 0.8864378063063575,\n",
       " 'eval_Precision': 0.881755457527429,\n",
       " 'eval_runtime': 89.737,\n",
       " 'eval_samples_per_second': 389.583,\n",
       " 'eval_steps_per_second': 6.096,\n",
       " 'epoch': 10.0}"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.evaluate(test_dataset_dna)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interpretation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, matthews_corrcoef, precision_score, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "34960"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_dataset_dna)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm, trange"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 39700/39700 [07:00<00:00, 94.36it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "y_true = []\n",
    "y_pred = []\n",
    "vals1 = set()\n",
    "vals2 = set()\n",
    "not_equal_count = 0\n",
    "accs = []\n",
    "press = []\n",
    "mccs = []\n",
    "f1s = []\n",
    "zdna_is = []\n",
    "t = 0\n",
    "for idx in trange(0, len(test_dataset_dna)):\n",
    "    element = test_dataset_dna[idx]\n",
    "    el = element\n",
    "    element_torch = {k: torch.tensor(v).unsqueeze(0).to(device) for k, v in element.items()}\n",
    "    token_ids = element['input_ids']\n",
    "    tokens = [id2label[id_] for id_ in token_ids]\n",
    "    interval = test_dataset_dna.intervals[idx]\n",
    "    chrom = interval[0]\n",
    "    begin = int(interval[1])\n",
    "    end = int(interval[2])\n",
    "    sequence = test_dataset_dna.dna_source[chrom][begin:end].upper()\n",
    "    # print(element_torch)\n",
    "    with torch.no_grad():\n",
    "        logits = model(**element_torch).logits\n",
    "    predictions = torch.argmax(logits.cpu(), dim=2)\n",
    "    pred_nucleotide = []\n",
    "    for i, pred in enumerate(predictions[0]):\n",
    "        if -100 != int(element['labels'][i]):\n",
    "            token_length = len(tokens[i])\n",
    "            for _ in range(token_length):\n",
    "                pred_nucleotide.append(int(pred))\n",
    "    \n",
    "    y = test_dataset_dna.labels[interval[0]][int(interval[1]):int(interval[2])]\n",
    "    if len(y) != len(pred_nucleotide):\n",
    "        print(len(y),len(pred_nucleotide))\n",
    "        print(\"Y:\", y)\n",
    "        print(\"Pred:\", pred_nucleotide)\n",
    "        print(\"TOK:\", ''.join(tokens))\n",
    "        print(\"SEQ:\", sequence)\n",
    "        print(\"--------\")\n",
    "        not_equal_count += 1\n",
    "    else:\n",
    "        t += 1\n",
    "        y_true.append(y)\n",
    "        y_pred.append(pred_nucleotide)\n",
    "    vals1.update(set(y))\n",
    "    vals2.update(set(pred_nucleotide))\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(39700, 70) (39700, 70)\n"
     ]
    }
   ],
   "source": [
    "y_true_arr = np.array(y_true)\n",
    "y_pred_arr = np.array(y_pred)\n",
    "print(y_true_arr.shape, y_pred_arr.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Getting metrics for single-nucleotide prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.984092479309104\n",
      "MCC: 0.8551746175877273\n",
      "Precision: 0.9024720006760139\n",
      "F1: 0.862662130885254\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy:\", accuracy_score(y_true_arr.flatten(), y_pred_arr.flatten()))\n",
    "print(\"MCC:\", matthews_corrcoef(y_true_arr.flatten(), y_pred_arr.flatten()))\n",
    "print(\"Precision:\", precision_score(y_true_arr.flatten(), y_pred_arr.flatten()))\n",
    "print(\"F1:\", f1_score(y_true_arr.flatten(), y_pred_arr.flatten()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Counting ratios."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "tp = ((y_true_arr.flatten() == 1) & (y_pred_arr.flatten() == 1)).sum()\n",
    "tn = ((y_true_arr.flatten() == 0) & (y_pred_arr.flatten() == 0)).sum()\n",
    "fp = ((y_true_arr.flatten() == 0) & (y_pred_arr.flatten() == 1)).sum()\n",
    "fn = ((y_true_arr.flatten() == 1) & (y_pred_arr.flatten() == 0)).sum()\n",
    "\n",
    "# Calculate ratios\n",
    "total = torch.tensor(len(y_true_arr.flatten()), dtype=torch.float)\n",
    "ratios = {\n",
    "    'TP': tp / total,\n",
    "    'TN': tn / total,\n",
    "    'FP': fp / total,\n",
    "    'FN': fn / total\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2778860.)"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'TP': tensor(0.0522),\n",
       " 'TN': tensor(0.9311),\n",
       " 'FP': tensor(0.0057),\n",
       " 'FN': tensor(0.0110)}"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratios"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Intergrated Gradients interpretation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 34959/34959 [06:59<00:00, 83.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "TP_counts = defaultdict(int)\n",
    "total_meetings_counts = defaultdict(int)\n",
    "\n",
    "\n",
    "for idx in trange(0, len(val_dataset_dna)):\n",
    "    element = val_dataset_dna[idx]\n",
    "    el = element\n",
    "    element_torch = {k: torch.tensor(v).unsqueeze(0).to(device) for k, v in element.items()}\n",
    "    token_ids = element['input_ids']\n",
    "    tokens = [id2label[id_] for id_ in token_ids]\n",
    "    interval = val_dataset_dna.intervals[idx]\n",
    "    chrom = interval[0]\n",
    "    begin = int(interval[1])\n",
    "    end = int(interval[2])\n",
    "    sequence = val_dataset_dna.dna_source[chrom][begin:end].upper()\n",
    "    with torch.no_grad():\n",
    "        logits = model(**element_torch).logits\n",
    "    predictions = torch.argmax(logits, dim=2)\n",
    "    pred_nucleotide = []\n",
    "    y = val_dataset_dna.labels[interval[0]][int(interval[1]):int(interval[2])]\n",
    "\n",
    "    curr_ind = 0\n",
    "    for tok_ind, token in enumerate(tokens):\n",
    "        label = element['labels'][tok_ind]\n",
    "        \n",
    "        pred = predictions[0][tok_ind]\n",
    "        total_meetings_counts[token] += 1\n",
    "        if pred == label and pred == 1:\n",
    "            TP_counts[token] += 1\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "percents = []\n",
    "for key, val in total_meetings_counts.items():\n",
    "    if total_meetings_counts[key] > 0:\n",
    "        percents.append((TP_counts[key] / total_meetings_counts[key], key))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0.8230088495575221, 'GCGCG'),\n",
       " (0.6916588566073102, 'GCGC'),\n",
       " (0.6564885496183206, 'GCACG'),\n",
       " (0.6036866359447005, 'ACGCG'),\n",
       " (0.5462962962962963, 'GCGTG'),\n",
       " (0.5042321644498187, 'TGCGC'),\n",
       " (0.4842055634134842, 'ACGC'),\n",
       " (0.44750656167979, 'GTGC'),\n",
       " (0.4251497005988024, 'GTGTG'),\n",
       " (0.4222950819672131, 'GCG')]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(sorted(percents)[::-1])[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Score</th>\n",
       "      <th>Token</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.823009</td>\n",
       "      <td>GCGCG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.691659</td>\n",
       "      <td>GCGC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.656489</td>\n",
       "      <td>GCACG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.603687</td>\n",
       "      <td>ACGCG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.546296</td>\n",
       "      <td>GCGTG</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Score  Token\n",
       "0  0.823009  GCGCG\n",
       "1  0.691659   GCGC\n",
       "2  0.656489  GCACG\n",
       "3  0.603687  ACGCG\n",
       "4  0.546296  GCGTG"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(sorted(percents)[::-1])\n",
    "df = df.rename(columns={0: 'Score', 1: 'Token'})\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Token</th>\n",
       "      <th>Counts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[CLS]</td>\n",
       "      <td>34959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>GGGGC</td>\n",
       "      <td>1190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>GCCC</td>\n",
       "      <td>1953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ATG</td>\n",
       "      <td>14650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TGCGC</td>\n",
       "      <td>827</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Token  Counts\n",
       "0  [CLS]   34959\n",
       "1  GGGGC    1190\n",
       "2   GCCC    1953\n",
       "3    ATG   14650\n",
       "4  TGCGC     827"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1 = pd.DataFrame(list(total_meetings_counts.items()))\n",
    "df1 = df1.rename(columns={0: 'Token', 1: 'Counts'})\n",
    "df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Token</th>\n",
       "      <th>Counts</th>\n",
       "      <th>Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[CLS]</td>\n",
       "      <td>34959</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>GGGGC</td>\n",
       "      <td>1190</td>\n",
       "      <td>0.171429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>GCCC</td>\n",
       "      <td>1953</td>\n",
       "      <td>0.263697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ATG</td>\n",
       "      <td>14650</td>\n",
       "      <td>0.026212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TGCGC</td>\n",
       "      <td>827</td>\n",
       "      <td>0.504232</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Token  Counts     Score\n",
       "0  [CLS]   34959  0.000000\n",
       "1  GGGGC    1190  0.171429\n",
       "2   GCCC    1953  0.263697\n",
       "3    ATG   14650  0.026212\n",
       "4  TGCGC     827  0.504232"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_merged = df1.merge(df, on=['Token'], how='left')\n",
    "df_merged.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Token</th>\n",
       "      <th>Counts</th>\n",
       "      <th>Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>287</th>\n",
       "      <td>GCGCG</td>\n",
       "      <td>339</td>\n",
       "      <td>0.823009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>GCGC</td>\n",
       "      <td>3201</td>\n",
       "      <td>0.691659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>GCACG</td>\n",
       "      <td>131</td>\n",
       "      <td>0.656489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>369</th>\n",
       "      <td>ACGCG</td>\n",
       "      <td>217</td>\n",
       "      <td>0.603687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>558</th>\n",
       "      <td>GCGTG</td>\n",
       "      <td>108</td>\n",
       "      <td>0.546296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>429</th>\n",
       "      <td>AATGG</td>\n",
       "      <td>774</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>433</th>\n",
       "      <td>GAACC</td>\n",
       "      <td>28</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>436</th>\n",
       "      <td>GTACC</td>\n",
       "      <td>25</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>438</th>\n",
       "      <td>CTTG</td>\n",
       "      <td>73</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>626</th>\n",
       "      <td>TTATA</td>\n",
       "      <td>9</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>627 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Token  Counts     Score\n",
       "287  GCGCG     339  0.823009\n",
       "146   GCGC    3201  0.691659\n",
       "197  GCACG     131  0.656489\n",
       "369  ACGCG     217  0.603687\n",
       "558  GCGTG     108  0.546296\n",
       "..     ...     ...       ...\n",
       "429  AATGG     774  0.000000\n",
       "433  GAACC      28  0.000000\n",
       "436  GTACC      25  0.000000\n",
       "438   CTTG      73  0.000000\n",
       "626  TTATA       9  0.000000\n",
       "\n",
       "[627 rows x 3 columns]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_merged.sort_values('Score', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged.sort_values('Score', ascending=False).to_csv(\"gena-lm-token-importance-max-110-510-5-03-06.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interpretation using integrated_gradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers_interpret import TokenClassificationExplainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "mce = TokenClassificationExplainer(model, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<transformers_interpret.explainers.text.token_classification.TokenClassificationExplainer at 0x2b1eed5f73d0>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_of_samples = 4000\n",
    "test_indexes = np.random.choice(len(test_dataset_dna), num_of_samples, replace=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_meetings_counts = defaultdict(int)\n",
    "TP_counts = defaultdict(int)\n",
    "positive_scores_sum = defaultdict(int)\n",
    "for sample_idx in trange(0, len(test_indexes)):\n",
    "    idx = test_indexes[sample_idx]\n",
    "    element = test_dataset_dna[idx]\n",
    "    el = element\n",
    "    element_torch = {k: torch.tensor(v).unsqueeze(0).to(device) for k, v in element.items()}\n",
    "    token_ids = element['input_ids']\n",
    "    tokens = [id2label[id_] for id_ in token_ids]\n",
    "    interval = test_dataset_dna.intervals[idx]\n",
    "    chrom = interval[0]\n",
    "    begin = int(interval[1])\n",
    "    end = int(interval[2])\n",
    "    sequence = test_dataset_dna.dna_source[chrom][begin:end].upper()\n",
    "    with torch.no_grad():\n",
    "        logits = model(**element_torch).logits\n",
    "    predictions = torch.argmax(logits, dim=2)\n",
    "    pred_nucleotide = []\n",
    "    y = test_dataset_dna.labels[interval[0]][int(interval[1]):int(interval[2])]\n",
    "    word_attributions = mce(sequence)\n",
    "    for tok_ind, token in enumerate(tokens):\n",
    "        label = element['labels'][tok_ind]\n",
    "        if label != -100:\n",
    "            pred = int(predictions[0][tok_ind])\n",
    "            if label == pred and label == 1:\n",
    "                # true positive\n",
    "                tokens_watch = sorted(word_attributions[token]['attribution_scores'], key=lambda x: x[1])[::-1][:10]\n",
    "                for helpful_token, helpful_token_score in tokens_watch:\n",
    "                    total_meetings_counts[helpful_token] += 1\n",
    "                    if pred == label and pred == 1:\n",
    "                        TP_counts[helpful_token] += 1\n",
    "                        positive_scores_sum[helpful_token] += helpful_token_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "integr_grad_result = []\n",
    "for token, count in TP_counts.items():\n",
    "    summa = positive_scores_sum[token]\n",
    "    integr_grad_result.append((summa / count, token))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Token</th>\n",
       "      <th>Count</th>\n",
       "      <th>Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>382</th>\n",
       "      <td>AAATC</td>\n",
       "      <td>1</td>\n",
       "      <td>0.957605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>GCGTG</td>\n",
       "      <td>28</td>\n",
       "      <td>0.803239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194</th>\n",
       "      <td>ACGCG</td>\n",
       "      <td>31</td>\n",
       "      <td>0.658981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>167</th>\n",
       "      <td>GCGCG</td>\n",
       "      <td>99</td>\n",
       "      <td>0.647458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>GCGC</td>\n",
       "      <td>982</td>\n",
       "      <td>0.558593</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Token  Count     Score\n",
       "382  AAATC      1  0.957605\n",
       "198  GCGTG     28  0.803239\n",
       "194  ACGCG     31  0.658981\n",
       "167  GCGCG     99  0.647458\n",
       "33    GCGC    982  0.558593"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_intr_gr = pd.DataFrame(sorted(integr_grad_result)[::-1])\n",
    "df_intr_gr = df_intr_gr.rename(columns={0: 'Score', 1: 'Token'})\n",
    "df_counts = pd.DataFrame(list(TP_counts.items()))\n",
    "df_counts = df_counts.rename(columns={0: 'Token', 1: 'Count'})\n",
    "df_intgr_merged = df_counts.merge(df_intr_gr, how='left', on='Token')\n",
    "df_intgr_merged = df_intgr_merged.sort_values('Score', ascending=False)\n",
    "df_intgr_merged.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_intgr_merged.to_csv('integrated_gradinents_scores_true_positive-5-3-stages.csv')"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "ymEUHL2C00xl"
   ],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Google Colab Analog 2024 (PyTorch 2.5.1 + TensorFlow 2.18) [python-google_colab_gpu_2024]",
   "language": "python",
   "name": "conda-env-python-google_colab_gpu_2024-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "0583c5d831f44fda9333482c164cdd82": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_06ba5278c20a49e4aaa1350594b1b4e1",
      "placeholder": "​",
      "style": "IPY_MODEL_be89bdebb7fe47b0befdd33c749a05b1",
      "value": " 359/? [00:00&lt;00:00, 37.0kB/s]"
     }
    },
    "06ba5278c20a49e4aaa1350594b1b4e1": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "0c620a2c08bc41dfa9cbf27b328a6cb5": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "1621dc2fa1554cfdae30335306f93763": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "180066dae7c046529accfb1cffaa374f": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "18b4a14066054a39ab41e19eb9fe17c1": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_4014d48cd385447aac51a92b7d0fbb7e",
      "placeholder": "​",
      "style": "IPY_MODEL_4e5cfa2aca3142a19134a471d67384b5",
      "value": "Map: 100%"
     }
    },
    "1ab55a1fd3f24b87bddb9d396e8b2a54": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_5dbcba54182f4afa8abdb85a5ffd1bc2",
       "IPY_MODEL_3f2a9451ad2e423f9afbc1d9330ac16b",
       "IPY_MODEL_21a4f1f0c259443ebad5ef1f99afbf24"
      ],
      "layout": "IPY_MODEL_e41e2ad66fa443dd8994f74676e2f27e"
     }
    },
    "1bea558dcbd9421a9a679452d78876e5": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_c159352da0544ac980fc2fbfae0cf55d",
       "IPY_MODEL_7d819d9b982647178bd52bf03ead8143",
       "IPY_MODEL_0583c5d831f44fda9333482c164cdd82"
      ],
      "layout": "IPY_MODEL_443da18f0ab2486489d51f0f6fffdcbb"
     }
    },
    "21a4f1f0c259443ebad5ef1f99afbf24": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_0c620a2c08bc41dfa9cbf27b328a6cb5",
      "placeholder": "​",
      "style": "IPY_MODEL_5e416e12728043b1bbf0567b5ffd221e",
      "value": " 18053/18053 [00:25&lt;00:00, 581.66 examples/s]"
     }
    },
    "241b014da3f6438683632233a6a68a50": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_18b4a14066054a39ab41e19eb9fe17c1",
       "IPY_MODEL_f9f5d597451241829fac1ad6d41ce259",
       "IPY_MODEL_f669b36445f24f9fa2a3d10f8a76b51a"
      ],
      "layout": "IPY_MODEL_d6f4c70e28d14c7cb429fb87aa8189aa"
     }
    },
    "2d2dc1f112b4446f9c02f48559769d5f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "33c99acaf0944fff97cd0c4b62f7f9d6": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "3bdb38bb971a49b7a97f0b83846079cf": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "3f2a9451ad2e423f9afbc1d9330ac16b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_33c99acaf0944fff97cd0c4b62f7f9d6",
      "max": 18053,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_1621dc2fa1554cfdae30335306f93763",
      "value": 18053
     }
    },
    "4014d48cd385447aac51a92b7d0fbb7e": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "4125cb8d6b914661883cac355144ceff": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "41611514492248bb97b7194fe17bf65f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "443da18f0ab2486489d51f0f6fffdcbb": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "4a2a7528ce99490fa246a075137dc2fe": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "4e5cfa2aca3142a19134a471d67384b5": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "54f640f27da5451a9a88cf9419827e1f": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "5dbcba54182f4afa8abdb85a5ffd1bc2": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_3bdb38bb971a49b7a97f0b83846079cf",
      "placeholder": "​",
      "style": "IPY_MODEL_2d2dc1f112b4446f9c02f48559769d5f",
      "value": "Map: 100%"
     }
    },
    "5e416e12728043b1bbf0567b5ffd221e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "630ddaa634574a62bfe5447d8774bb25": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "7d819d9b982647178bd52bf03ead8143": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_180066dae7c046529accfb1cffaa374f",
      "max": 219,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_4a2a7528ce99490fa246a075137dc2fe",
      "value": 219
     }
    },
    "be89bdebb7fe47b0befdd33c749a05b1": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "c159352da0544ac980fc2fbfae0cf55d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_f772f9d33db747b4b8b7560aaf533e78",
      "placeholder": "​",
      "style": "IPY_MODEL_cf9278a50d154cd396d4c67ce697e2fe",
      "value": "(…)dnabert-config/bert-config-6/config.json: "
     }
    },
    "cf9278a50d154cd396d4c67ce697e2fe": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "d6f4c70e28d14c7cb429fb87aa8189aa": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e41e2ad66fa443dd8994f74676e2f27e": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f669b36445f24f9fa2a3d10f8a76b51a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_630ddaa634574a62bfe5447d8774bb25",
      "placeholder": "​",
      "style": "IPY_MODEL_41611514492248bb97b7194fe17bf65f",
      "value": " 20000/20000 [00:44&lt;00:00, 448.49 examples/s]"
     }
    },
    "f772f9d33db747b4b8b7560aaf533e78": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f9f5d597451241829fac1ad6d41ce259": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_54f640f27da5451a9a88cf9419827e1f",
      "max": 20000,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_4125cb8d6b914661883cac355144ceff",
      "value": 20000
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
